{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:40:28] {comtypes.client._code_cache:95} INFO - Imported existing <module 'comtypes.gen' from 'c:\\\\Users\\\\mirandaa\\\\Anaconda3\\\\envs\\\\lx128_p3_Dev\\\\lib\\\\site-packages\\\\comtypes\\\\gen\\\\__init__.py'>\n",
      "[11:40:28] {comtypes.client._code_cache:72} INFO - Using writeable comtypes cache directory: 'c:\\Users\\mirandaa\\Anaconda3\\envs\\lx128_p3_Dev\\lib\\site-packages\\comtypes\\gen'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from LX2_masterscan import mz_ml_paths, spectra_2_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('optoins.pkl','rb') as f: options = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mzmls = mz_ml_paths(options)\n",
    "samples = [p.stem for p in mzmls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:40:51] {ms_deisotope.data_source.scan.loader:376} INFO - Disposing of MzMLLoader('test_resources\\\\small_test\\\\190321_Serum_Lipidextract_368723_01.mzML') with 2 extant scans attached to it.\n",
      "[11:40:52] {LX2_masterscan:304} INFO - spectra 190321_Serum_Lipidextract_368723_01, size: (368085, 8)\n",
      "[11:41:07] {ms_deisotope.data_source.scan.loader:376} INFO - Disposing of MzMLLoader('test_resources\\\\small_test\\\\190321_Serum_Lipidextract_368723_02.mzML') with 2 extant scans attached to it.\n",
      "[11:41:07] {LX2_masterscan:304} INFO - spectra 190321_Serum_Lipidextract_368723_02, size: (389793, 8)\n"
     ]
    }
   ],
   "source": [
    "spectra_dfs = spectra_2_df(options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spectra_df in spectra_dfs:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_selection_window (spectra_df):\n",
    "    precursor_mzs = spectra_df.loc[~spectra_df.precursor_id.isna()].precursor_mz.drop_duplicates()\n",
    "    precursor_mzs.sort_values(inplace=True)\n",
    "    agg_data = precursor_mzs.diff().agg(['mean','std'])\n",
    "\n",
    "    mean_less_std = agg_data.at['mean'] - agg_data.at['std']\n",
    "    if mean_less_std > 0:\n",
    "        res =  mean_less_std / 2\n",
    "    else:\n",
    "        res =  agg_data.at['mean'] /2\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suggest tolerance\n",
    "# sugest calibration masses using suggested tolerance\n",
    "scan_count = spectra_df.loc[spectra_df.precursor_id.isna()].scan_id.unique().size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spectra_df.loc[spectra_df.precursor_id.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mirandaa\\Anaconda3\\envs\\lx128_p3_Dev\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df.sort_values('mz', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_linear_alignment(masses, options):\n",
    "    # TODO assert masses are ordered\n",
    "    up_to = None\n",
    "    for _, mass in masses.iteritems():\n",
    "        if up_to is None:\n",
    "            #up_to = mass + tolerance.getTinDA(mass) this is how its done in some places, but reuslt are not identical to below\n",
    "            up_to = mass + mass / options[\"MSresolution\"].tolerance \n",
    "        if mass <= up_to:\n",
    "            yield up_to\n",
    "        else:\n",
    "            up_to = mass + mass / options[\"MSresolution\"].tolerance\n",
    "            yield up_to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mirandaa\\Anaconda3\\envs\\lx128_p3_Dev\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "bins1 = list(bin_linear_alignment(df.mz, options))\n",
    "bins2 = list(bin_linear_alignment(df.groupby(bins1)[\"mz\"].transform(\"mean\"), options))\n",
    "bins3 = list(bin_linear_alignment(df.groupby(bins2)[\"mz\"].transform(\"mean\"),options))\n",
    "\n",
    "df['bin_mass'] = bins3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mirandaa\\Anaconda3\\envs\\lx128_p3_Dev\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\Users\\mirandaa\\Anaconda3\\envs\\lx128_p3_Dev\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\Users\\mirandaa\\Anaconda3\\envs\\lx128_p3_Dev\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df.sort_values('mz', ascending = False, inplace=True)\n",
    "# repetition_rate = 0.7\n",
    "scan_count = df.scan_id.unique().size\n",
    "df['mz_diff'] = df.mz.diff(-1)\n",
    "df['mz_diff_long'] = df['mz_diff'].rolling(scan_count).mean() # neg because of sorting order\n",
    "# short_count = scan_count * repetition_rate\n",
    "# df['mz_diff_short'] = df.mz.diff().rolling(int(short_count)).mean()\n",
    "# df['scan_id_f'] = df['scan_id'].factorize()[0]\n",
    "# df['scan_cnt'] = df.scan_id_f.rolling(scan_count).apply(lambda s: len(set(s)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def diff_bin(df):\n",
    "\n",
    "    cur_bin = 0\n",
    "    curr_long = 0.01\n",
    "\n",
    "    for tup in df.itertuples():\n",
    "        yield cur_bin\n",
    "        if tup.mz_diff > curr_long:\n",
    "            cur_bin +=1\n",
    "        \n",
    "        if tup.mz_diff_long < curr_long:\n",
    "            curr_long = tup.mz_diff_long\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mirandaa\\Anaconda3\\envs\\lx128_p3_Dev\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['diff_bin'] = list(diff_bin(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collapsable_bins(df):\n",
    "    df['scan_id_f'] = df['scan_id'].factorize()[0]\n",
    "    grouped = df.groupby('diff_bin')\n",
    "    grouped_stats = grouped.agg({'mz':['max','min','std']})\n",
    "    close_mz = grouped_stats[('mz','min')] - grouped_stats[('mz','max')].shift(-1) < grouped_stats[('mz','std')] + grouped_stats[('mz','std')].shift(-1)\n",
    "    close_mz_groups = close_mz[close_mz | close_mz.shift(1)].index.to_numpy()\n",
    "    close_sets = df.loc[df.diff_bin.isin(close_mz_groups)].groupby('diff_bin')['scan_id_f'].apply(lambda s:set(s))\n",
    "\n",
    "    collapsable_map = {}\n",
    "    prev_set = set()\n",
    "    prev_idx = 0\n",
    "    merging = False\n",
    "    for idx, curr_set in close_sets.iteritems():\n",
    "        if (idx - prev_idx <=1 or merging) and not curr_set.intersection(prev_set):\n",
    "            collapsable_map[idx] = prev_idx\n",
    "            prev_set.update(curr_set)\n",
    "            merging = True\n",
    "        prev_idx = idx\n",
    "        prev_set = curr_set\n",
    "        merging = False\n",
    "    \n",
    "    return collapsable_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mirandaa\\Anaconda3\\envs\\lx128_p3_Dev\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['scan_id_f'] = df['scan_id'].factorize()[0]\n",
    "grouped = df.groupby('diff_bin')\n",
    "grouped_stats = grouped.agg({'mz':['max','min','std']})\n",
    "close_mz = grouped_stats[('mz','min')] - grouped_stats[('mz','max')].shift(-1) < grouped_stats[('mz','std')] + grouped_stats[('mz','std')].shift(-1)\n",
    "close_mz_groups = close_mz[close_mz | close_mz.shift(1)].index.to_numpy()\n",
    "close_sets = df.loc[df.diff_bin.isin(close_mz_groups)].groupby('diff_bin')['scan_id_f'].apply(lambda s:set(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = {}\n",
    "prev_set = set()\n",
    "prev_idx = 0\n",
    "merging = False\n",
    "for idx, curr_set in close_sets.iteritems():\n",
    "    if (idx - prev_idx <=1 or merging) and not curr_set.intersection(prev_set):\n",
    "        res[idx] = prev_idx\n",
    "        prev_set.update(curr_set)\n",
    "        merging = True\n",
    "    prev_idx = idx\n",
    "    prev_set = curr_set\n",
    "    merging = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{74: 73,\n",
       " 119: 118,\n",
       " 169: 168,\n",
       " 356: 355,\n",
       " 389: 388,\n",
       " 393: 392,\n",
       " 438: 437,\n",
       " 468: 467,\n",
       " 481: 480,\n",
       " 503: 502,\n",
       " 567: 566,\n",
       " 577: 576,\n",
       " 585: 584,\n",
       " 601: 600,\n",
       " 622: 621,\n",
       " 635: 634,\n",
       " 638: 637,\n",
       " 642: 641,\n",
       " 654: 653,\n",
       " 655: 654,\n",
       " 682: 681,\n",
       " 692: 691,\n",
       " 694: 693,\n",
       " 716: 715,\n",
       " 718: 717,\n",
       " 747: 746,\n",
       " 749: 748,\n",
       " 788: 787,\n",
       " 806: 805,\n",
       " 844: 843,\n",
       " 861: 860,\n",
       " 872: 871,\n",
       " 897: 896,\n",
       " 901: 900,\n",
       " 908: 907,\n",
       " 909: 908,\n",
       " 910: 909,\n",
       " 945: 944,\n",
       " 950: 949,\n",
       " 1014: 1013,\n",
       " 1029: 1028,\n",
       " 1030: 1029,\n",
       " 1045: 1044,\n",
       " 1047: 1046,\n",
       " 1072: 1071,\n",
       " 1089: 1088,\n",
       " 1098: 1097,\n",
       " 1110: 1109,\n",
       " 1117: 1116,\n",
       " 1131: 1130,\n",
       " 1137: 1136,\n",
       " 1197: 1196,\n",
       " 1221: 1220,\n",
       " 1239: 1238,\n",
       " 1241: 1240,\n",
       " 1259: 1258,\n",
       " 1286: 1285,\n",
       " 1300: 1299,\n",
       " 1311: 1310,\n",
       " 1343: 1342,\n",
       " 1355: 1354,\n",
       " 1405: 1404,\n",
       " 1413: 1412,\n",
       " 1434: 1433,\n",
       " 1472: 1471,\n",
       " 1489: 1488,\n",
       " 1494: 1493,\n",
       " 1506: 1505,\n",
       " 1513: 1512,\n",
       " 1515: 1514,\n",
       " 1524: 1523,\n",
       " 1544: 1543,\n",
       " 1581: 1580,\n",
       " 1589: 1588,\n",
       " 1603: 1602,\n",
       " 1612: 1611,\n",
       " 1627: 1626,\n",
       " 1715: 1714,\n",
       " 1728: 1727,\n",
       " 1817: 1816,\n",
       " 1821: 1820,\n",
       " 1850: 1849,\n",
       " 1851: 1850,\n",
       " 1852: 1851,\n",
       " 1853: 1852,\n",
       " 1875: 1874,\n",
       " 1895: 1894,\n",
       " 1900: 1899,\n",
       " 1924: 1923,\n",
       " 1925: 1924,\n",
       " 1926: 1925,\n",
       " 1967: 1966,\n",
       " 1975: 1974,\n",
       " 1984: 1983,\n",
       " 1988: 1987,\n",
       " 1993: 1992,\n",
       " 2015: 2014,\n",
       " 2048: 2047,\n",
       " 2058: 2057,\n",
       " 2066: 2065,\n",
       " 2107: 2106,\n",
       " 2108: 2107,\n",
       " 2134: 2133,\n",
       " 2182: 2181,\n",
       " 2183: 2182,\n",
       " 2203: 2202,\n",
       " 2211: 2210,\n",
       " 2229: 2228,\n",
       " 2238: 2237,\n",
       " 2242: 2241,\n",
       " 2246: 2245,\n",
       " 2281: 2280,\n",
       " 2286: 2285,\n",
       " 2310: 2309,\n",
       " 2321: 2320,\n",
       " 2342: 2341,\n",
       " 2343: 2342,\n",
       " 2381: 2380,\n",
       " 2395: 2394,\n",
       " 2396: 2395,\n",
       " 2413: 2412,\n",
       " 2414: 2413,\n",
       " 2424: 2423,\n",
       " 2432: 2431,\n",
       " 2443: 2442,\n",
       " 2451: 2450,\n",
       " 2452: 2451,\n",
       " 2461: 2460,\n",
       " 2482: 2481,\n",
       " 2523: 2522,\n",
       " 2530: 2529,\n",
       " 2535: 2534,\n",
       " 2542: 2541,\n",
       " 2552: 2551,\n",
       " 2560: 2559,\n",
       " 2592: 2591,\n",
       " 2606: 2605,\n",
       " 2614: 2613,\n",
       " 2635: 2634,\n",
       " 2666: 2665,\n",
       " 2667: 2666,\n",
       " 2685: 2684,\n",
       " 2724: 2723,\n",
       " 2731: 2730,\n",
       " 2734: 2733,\n",
       " 2746: 2745,\n",
       " 2749: 2748,\n",
       " 2764: 2763,\n",
       " 2765: 2764,\n",
       " 2773: 2772,\n",
       " 2779: 2778,\n",
       " 2782: 2781,\n",
       " 2796: 2795,\n",
       " 2841: 2840,\n",
       " 2844: 2843,\n",
       " 2872: 2871,\n",
       " 2891: 2890,\n",
       " 2902: 2901,\n",
       " 2928: 2927,\n",
       " 2952: 2951,\n",
       " 2958: 2957,\n",
       " 3012: 3011,\n",
       " 3039: 3038,\n",
       " 3068: 3067,\n",
       " 3073: 3072,\n",
       " 3102: 3101,\n",
       " 3109: 3108,\n",
       " 3161: 3160,\n",
       " 3167: 3166,\n",
       " 3168: 3167,\n",
       " 3169: 3168,\n",
       " 3178: 3177,\n",
       " 3233: 3232,\n",
       " 3260: 3259,\n",
       " 3290: 3289,\n",
       " 3291: 3290,\n",
       " 3302: 3301,\n",
       " 3334: 3333,\n",
       " 3357: 3356,\n",
       " 3358: 3357,\n",
       " 3366: 3365,\n",
       " 3367: 3366,\n",
       " 3368: 3367,\n",
       " 3375: 3374,\n",
       " 3437: 3436,\n",
       " 3438: 3437,\n",
       " 3478: 3477,\n",
       " 3481: 3480,\n",
       " 3488: 3487,\n",
       " 3505: 3504,\n",
       " 3506: 3505,\n",
       " 3516: 3515,\n",
       " 3522: 3521,\n",
       " 3530: 3529,\n",
       " 3531: 3530,\n",
       " 3556: 3555,\n",
       " 3560: 3559,\n",
       " 3570: 3569,\n",
       " 3571: 3570,\n",
       " 3626: 3625,\n",
       " 3628: 3627,\n",
       " 3629: 3628,\n",
       " 3651: 3650,\n",
       " 3665: 3664,\n",
       " 3677: 3676,\n",
       " 3694: 3693,\n",
       " 3714: 3713,\n",
       " 3755: 3754,\n",
       " 3770: 3769,\n",
       " 3778: 3777,\n",
       " 3810: 3809,\n",
       " 3816: 3815,\n",
       " 3820: 3819,\n",
       " 3827: 3826,\n",
       " 3836: 3835,\n",
       " 3856: 3855,\n",
       " 3876: 3875,\n",
       " 3879: 3878,\n",
       " 3890: 3889,\n",
       " 3897: 3896,\n",
       " 3908: 3907,\n",
       " 3916: 3915,\n",
       " 3927: 3926,\n",
       " 3932: 3931,\n",
       " 3958: 3957,\n",
       " 3974: 3973,\n",
       " 4007: 4006,\n",
       " 4013: 4012,\n",
       " 4043: 4042,\n",
       " 4049: 4048,\n",
       " 4082: 4081,\n",
       " 4083: 4082,\n",
       " 4092: 4091,\n",
       " 4103: 4102,\n",
       " 4122: 4121,\n",
       " 4123: 4122,\n",
       " 4133: 4132,\n",
       " 4150: 4149,\n",
       " 4154: 4153,\n",
       " 4164: 4163,\n",
       " 4184: 4183,\n",
       " 4191: 4190,\n",
       " 4195: 4194,\n",
       " 4199: 4198,\n",
       " 4200: 4199,\n",
       " 4215: 4214,\n",
       " 4250: 4249,\n",
       " 4268: 4267,\n",
       " 4295: 4294,\n",
       " 4306: 4305,\n",
       " 4309: 4308,\n",
       " 4310: 4309,\n",
       " 4357: 4356,\n",
       " 4371: 4370,\n",
       " 4378: 4377,\n",
       " 4408: 4407,\n",
       " 4431: 4430,\n",
       " 4433: 4432,\n",
       " 4446: 4445,\n",
       " 4461: 4460,\n",
       " 4470: 4469,\n",
       " 4485: 4484,\n",
       " 4510: 4509,\n",
       " 4559: 4558,\n",
       " 4574: 4573,\n",
       " 4600: 4599,\n",
       " 4604: 4603,\n",
       " 4617: 4616,\n",
       " 4626: 4625,\n",
       " 4627: 4626,\n",
       " 4648: 4647,\n",
       " 4671: 4670,\n",
       " 4674: 4673,\n",
       " 4696: 4695,\n",
       " 4710: 4709,\n",
       " 4738: 4737,\n",
       " 4743: 4742,\n",
       " 4752: 4751,\n",
       " 4758: 4757,\n",
       " 4775: 4774,\n",
       " 4794: 4793,\n",
       " 4797: 4796,\n",
       " 4798: 4797,\n",
       " 4831: 4830,\n",
       " 4842: 4841,\n",
       " 4848: 4847,\n",
       " 4890: 4889,\n",
       " 4914: 4913,\n",
       " 4915: 4914,\n",
       " 4927: 4926,\n",
       " 4928: 4927,\n",
       " 4937: 4936,\n",
       " 4946: 4945,\n",
       " 4983: 4982,\n",
       " 4995: 4994,\n",
       " 5008: 5007,\n",
       " 5019: 5018,\n",
       " 5031: 5030,\n",
       " 5037: 5036,\n",
       " 5065: 5064,\n",
       " 5071: 5070,\n",
       " 5075: 5074,\n",
       " 5129: 5128,\n",
       " 5175: 5174,\n",
       " 5180: 5179,\n",
       " 5202: 5201,\n",
       " 5265: 5264,\n",
       " 5271: 5270,\n",
       " 5312: 5311,\n",
       " 5347: 5346,\n",
       " 5361: 5360,\n",
       " 5391: 5390,\n",
       " 5419: 5418,\n",
       " 5432: 5431,\n",
       " 5438: 5437,\n",
       " 5466: 5465,\n",
       " 5483: 5482,\n",
       " 5496: 5495,\n",
       " 5505: 5504,\n",
       " 5506: 5505,\n",
       " 5538: 5537,\n",
       " 5560: 5559,\n",
       " 5571: 5570,\n",
       " 5602: 5601,\n",
       " 5634: 5633,\n",
       " 5677: 5676,\n",
       " 5695: 5694,\n",
       " 5714: 5713,\n",
       " 5727: 5726,\n",
       " 5783: 5782,\n",
       " 5809: 5808,\n",
       " 5810: 5809,\n",
       " 5827: 5826,\n",
       " 5872: 5871,\n",
       " 5889: 5888,\n",
       " 5903: 5902,\n",
       " 5908: 5907,\n",
       " 5951: 5950,\n",
       " 5976: 5975,\n",
       " 6010: 6009,\n",
       " 6011: 6010,\n",
       " 6021: 6020,\n",
       " 6058: 6057,\n",
       " 6072: 6071,\n",
       " 6121: 6120,\n",
       " 6127: 6126,\n",
       " 6128: 6127,\n",
       " 6172: 6171,\n",
       " 6203: 6202,\n",
       " 6230: 6229,\n",
       " 6257: 6256,\n",
       " 6275: 6274,\n",
       " 6288: 6287,\n",
       " 6295: 6294,\n",
       " 6296: 6295,\n",
       " 6327: 6326,\n",
       " 6331: 6330,\n",
       " 6373: 6372,\n",
       " 6392: 6391,\n",
       " 6428: 6427,\n",
       " 6440: 6439,\n",
       " 6447: 6446,\n",
       " 6453: 6452,\n",
       " 6457: 6456,\n",
       " 6494: 6493,\n",
       " 6495: 6494,\n",
       " 6508: 6507,\n",
       " 6522: 6521,\n",
       " 6537: 6536,\n",
       " 6541: 6540,\n",
       " 6584: 6583,\n",
       " 6589: 6588,\n",
       " 6590: 6589,\n",
       " 6611: 6610,\n",
       " 6618: 6617,\n",
       " 6631: 6630,\n",
       " 6637: 6636,\n",
       " 6638: 6637,\n",
       " 6646: 6645,\n",
       " 6660: 6659,\n",
       " 6707: 6706,\n",
       " 6746: 6745,\n",
       " 6750: 6749,\n",
       " 6771: 6770,\n",
       " 6795: 6794,\n",
       " 6801: 6800,\n",
       " 6822: 6821,\n",
       " 6858: 6857,\n",
       " 6862: 6861,\n",
       " 6869: 6868,\n",
       " 6875: 6874,\n",
       " 6876: 6875,\n",
       " 6882: 6881,\n",
       " 6923: 6922,\n",
       " 6955: 6954,\n",
       " 6980: 6979,\n",
       " 6987: 6986,\n",
       " 6988: 6987,\n",
       " 6996: 6995,\n",
       " 7066: 7065,\n",
       " 7111: 7110,\n",
       " 7147: 7146,\n",
       " 7151: 7150,\n",
       " 7196: 7195,\n",
       " 7199: 7198,\n",
       " 7248: 7247,\n",
       " 7254: 7253,\n",
       " 7270: 7269,\n",
       " 7281: 7280,\n",
       " 7354: 7353,\n",
       " 7361: 7360,\n",
       " 7369: 7368,\n",
       " 7392: 7391,\n",
       " 7439: 7438,\n",
       " 7457: 7456,\n",
       " 7458: 7457,\n",
       " 7461: 7460,\n",
       " 7477: 7476,\n",
       " 7483: 7482,\n",
       " 7544: 7543,\n",
       " 7559: 7558,\n",
       " 7589: 7588,\n",
       " 7618: 7617,\n",
       " 7633: 7632,\n",
       " 7638: 7637,\n",
       " 7695: 7694,\n",
       " 7757: 7756,\n",
       " 7761: 7760,\n",
       " 7780: 7779,\n",
       " 7781: 7780,\n",
       " 7799: 7798,\n",
       " 7819: 7818,\n",
       " 7820: 7819,\n",
       " 7829: 7828,\n",
       " 7874: 7873,\n",
       " 7916: 7915,\n",
       " 7962: 7961,\n",
       " 7997: 7996,\n",
       " 8009: 8008,\n",
       " 8021: 8020,\n",
       " 8031: 8030,\n",
       " 8037: 8036,\n",
       " 8038: 8037,\n",
       " 8083: 8082,\n",
       " 8084: 8083,\n",
       " 8097: 8096,\n",
       " 8134: 8133,\n",
       " 8141: 8140,\n",
       " 8142: 8141,\n",
       " 8158: 8157,\n",
       " 8159: 8158,\n",
       " 8191: 8190,\n",
       " 8208: 8207,\n",
       " 8217: 8216,\n",
       " 8218: 8217,\n",
       " 8221: 8220,\n",
       " 8226: 8225,\n",
       " 8300: 8299,\n",
       " 8310: 8309,\n",
       " 8322: 8321,\n",
       " 8323: 8322,\n",
       " 8328: 8327,\n",
       " 8341: 8340,\n",
       " 8351: 8350,\n",
       " 8386: 8385,\n",
       " 8428: 8427,\n",
       " 8493: 8492,\n",
       " 8575: 8574,\n",
       " 8576: 8575,\n",
       " 8577: 8576,\n",
       " 8578: 8577,\n",
       " 8579: 8578,\n",
       " 8587: 8586,\n",
       " 8638: 8637,\n",
       " 8672: 8671,\n",
       " 8676: 8675,\n",
       " 8702: 8701,\n",
       " 8710: 8709,\n",
       " 8735: 8734,\n",
       " 8741: 8740,\n",
       " 8786: 8785,\n",
       " 8799: 8798,\n",
       " 8814: 8813,\n",
       " 8815: 8814,\n",
       " 8872: 8871,\n",
       " 8897: 8896,\n",
       " 8922: 8921,\n",
       " 8958: 8957,\n",
       " 8980: 8979,\n",
       " 8992: 8991,\n",
       " 9001: 9000,\n",
       " 9019: 9018,\n",
       " 9051: 9050,\n",
       " 9062: 9061,\n",
       " 9075: 9074,\n",
       " 9155: 9154,\n",
       " 9190: 9189,\n",
       " 9197: 9196,\n",
       " 9213: 9212,\n",
       " 9214: 9213,\n",
       " 9218: 9217,\n",
       " 9297: 9296,\n",
       " 9362: 9361,\n",
       " 9370: 9369,\n",
       " 9373: 9372,\n",
       " 9381: 9380,\n",
       " 9397: 9396,\n",
       " 9459: 9458,\n",
       " 9504: 9503,\n",
       " 9508: 9507,\n",
       " 9614: 9613,\n",
       " 9619: 9618,\n",
       " 9620: 9619,\n",
       " 9660: 9659,\n",
       " 9667: 9666,\n",
       " 9671: 9670,\n",
       " 9691: 9690,\n",
       " 9702: 9701,\n",
       " 9756: 9755,\n",
       " 9758: 9757,\n",
       " 9799: 9798,\n",
       " 9807: 9806,\n",
       " 9808: 9807,\n",
       " 9825: 9824,\n",
       " 9838: 9837,\n",
       " 9839: 9838,\n",
       " 9857: 9856,\n",
       " 9858: 9857,\n",
       " 9869: 9868,\n",
       " 9887: 9886,\n",
       " 9891: 9890,\n",
       " 9926: 9925,\n",
       " 9948: 9947,\n",
       " 10005: 10004,\n",
       " 10037: 10036,\n",
       " 10057: 10056,\n",
       " 10065: 10064,\n",
       " 10078: 10077,\n",
       " 10098: 10097,\n",
       " 10133: 10132,\n",
       " 10157: 10156,\n",
       " 10172: 10171,\n",
       " 10182: 10181,\n",
       " 10208: 10207,\n",
       " 10209: 10208,\n",
       " 10234: 10233,\n",
       " 10263: 10262,\n",
       " 10280: 10279,\n",
       " 10301: 10300,\n",
       " 10302: 10301,\n",
       " 10312: 10311,\n",
       " 10372: 10371,\n",
       " 10373: 10372,\n",
       " 10397: 10396,\n",
       " 10431: 10430,\n",
       " 10456: 10455,\n",
       " 10492: 10491,\n",
       " 10513: 10512,\n",
       " 10627: 10626,\n",
       " 10722: 10721,\n",
       " 10723: 10722,\n",
       " 10735: 10734,\n",
       " 10769: 10768,\n",
       " 10783: 10782,\n",
       " 10799: 10798,\n",
       " 10816: 10815,\n",
       " 10832: 10831,\n",
       " 10860: 10859,\n",
       " 10868: 10867,\n",
       " 10880: 10879,\n",
       " 10889: 10888,\n",
       " 10922: 10921,\n",
       " 10950: 10949,\n",
       " 10951: 10950,\n",
       " 10969: 10968,\n",
       " 10972: 10971,\n",
       " 11037: 11036,\n",
       " 11044: 11043,\n",
       " 11056: 11055,\n",
       " 11063: 11062,\n",
       " 11073: 11072,\n",
       " 11084: 11083,\n",
       " 11147: 11146,\n",
       " 11190: 11189,\n",
       " 11199: 11198,\n",
       " 11262: 11261,\n",
       " 11300: 11299,\n",
       " 11304: 11303,\n",
       " 11380: 11379,\n",
       " 11381: 11380,\n",
       " 11385: 11384,\n",
       " 11386: 11385,\n",
       " 11455: 11454,\n",
       " 11457: 11456,\n",
       " 11498: 11497,\n",
       " 11522: 11521,\n",
       " 11609: 11608,\n",
       " 11617: 11616,\n",
       " 11627: 11626,\n",
       " 11630: 11629,\n",
       " 11636: 11635,\n",
       " 11641: 11640,\n",
       " 11646: 11645,\n",
       " 11674: 11673,\n",
       " 11722: 11721,\n",
       " 11756: 11755,\n",
       " 11785: 11784,\n",
       " 11796: 11795,\n",
       " 11818: 11817,\n",
       " 11858: 11857,\n",
       " 11861: 11860,\n",
       " 11872: 11871,\n",
       " 11873: 11872,\n",
       " 11901: 11900,\n",
       " 11946: 11945,\n",
       " 11970: 11969,\n",
       " 11983: 11982,\n",
       " 12002: 12001,\n",
       " 12016: 12015,\n",
       " 12031: 12030,\n",
       " 12054: 12053,\n",
       " 12058: 12057,\n",
       " 12072: 12071,\n",
       " 12080: 12079,\n",
       " 12147: 12146,\n",
       " 12153: 12152,\n",
       " 12158: 12157,\n",
       " 12169: 12168,\n",
       " 12180: 12179,\n",
       " 12199: 12198,\n",
       " 12237: 12236,\n",
       " 12247: 12246,\n",
       " 12277: 12276,\n",
       " 12303: 12302,\n",
       " 12315: 12314,\n",
       " 12321: 12320,\n",
       " 12448: 12447,\n",
       " 12449: 12448,\n",
       " 12450: 12449,\n",
       " 12451: 12450,\n",
       " 12462: 12461,\n",
       " 12473: 12472,\n",
       " 12475: 12474,\n",
       " 12491: 12490,\n",
       " 12500: 12499,\n",
       " 12518: 12517,\n",
       " 12519: 12518,\n",
       " 12520: 12519,\n",
       " 12546: 12545,\n",
       " 12572: 12571,\n",
       " 12613: 12612,\n",
       " 12665: 12664,\n",
       " 12671: 12670,\n",
       " 12678: 12677,\n",
       " 12681: 12680,\n",
       " 12701: 12700,\n",
       " 12711: 12710,\n",
       " 12741: 12740,\n",
       " 12797: 12796,\n",
       " 12831: 12830,\n",
       " 12845: 12844,\n",
       " 12913: 12912,\n",
       " 12963: 12962,\n",
       " 12984: 12983,\n",
       " 13019: 13018,\n",
       " 13021: 13020,\n",
       " 13022: 13021,\n",
       " 13226: 13225,\n",
       " 13289: 13288,\n",
       " 13298: 13297,\n",
       " 13299: 13298,\n",
       " 13300: 13299,\n",
       " 13342: 13341,\n",
       " 13413: 13412,\n",
       " 13437: 13436,\n",
       " 13486: 13485,\n",
       " 13540: 13539,\n",
       " 13552: 13551,\n",
       " 13560: 13559,\n",
       " 13598: 13597,\n",
       " 13658: 13657,\n",
       " 13668: 13667,\n",
       " 13672: 13671,\n",
       " 13750: 13749,\n",
       " 13759: 13758,\n",
       " 13794: 13793,\n",
       " 13823: 13822,\n",
       " 13876: 13875,\n",
       " 13885: 13884,\n",
       " 13932: 13931,\n",
       " 13966: 13965,\n",
       " 13967: 13966,\n",
       " 13991: 13990,\n",
       " 14013: 14012,\n",
       " 14047: 14046,\n",
       " 14103: 14102,\n",
       " 14108: 14107,\n",
       " 14145: 14144,\n",
       " 14147: 14146,\n",
       " 14152: 14151,\n",
       " 14157: 14156,\n",
       " 14164: 14163,\n",
       " 14182: 14181,\n",
       " 14216: 14215,\n",
       " 14253: 14252,\n",
       " 14297: 14296,\n",
       " 14366: 14365,\n",
       " 14370: 14369,\n",
       " 14451: 14450,\n",
       " 14484: 14483,\n",
       " 14509: 14508,\n",
       " 14531: 14530,\n",
       " 14559: 14558,\n",
       " 14580: 14579,\n",
       " 14640: 14639,\n",
       " 14726: 14725,\n",
       " 14749: 14748,\n",
       " 14773: 14772,\n",
       " 14785: 14784,\n",
       " 14874: 14873,\n",
       " 14879: 14878,\n",
       " 14882: 14881}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for merge collapse\n",
    "df['scan_id_f'] = df['scan_id'].factorize()[0]\n",
    "sets = df.groupby('diff_bin')['scan_id_f'].apply(lambda s:set(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prev_intersetct(sets):\n",
    "    prev = set()\n",
    "    for curr in sets:\n",
    "        yield(curr.intersection(prev))\n",
    "        prev = curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ints = list(prev_intersetct(sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "prev_scan_id_set = ()\n",
    "prev_min = 100_000\n",
    "prev_std = 0\n",
    "prev_cluster = 0\n",
    "for idx, gdf in df.groupby('diff_bin'):\n",
    "    if prev_min - gdf.mz.max() < prev_std + gdf.mz.std():\n",
    "        curr_set = set(gdf.scan_id_f)\n",
    "        if not curr_set.intersection(prev_scan_id_set):\n",
    "            prev_scan_id_set.update(curr_set)\n",
    "            res.append((idx,prev_cluster))\n",
    "        #candidarte\n",
    "    else:\n",
    "        prev_cluster = idx\n",
    "        prev_std = gdf.mz.std()\n",
    "        prev_min = gdf.mz.min()\n",
    "        prev_scan_id_set = set(gdf.scan_id_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scan_cnt'] = df.scan_id_f.rolling(scan_count).apply(lambda s: len(set(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scan_id_f'] = df['scan_id'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(['mz','scan_id_f'], ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mz_diff_31'] = df.mz.diff(-31)\n",
    "df['mz_diff_20'] = df.mz.diff(-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mz_diff_31_cummin']= df['mz_diff_31'].cummin()\n",
    "df['mz_diff_20_cummin']= df['mz_diff_20'].cummin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.mz_diff_20 <= df.mz_diff_20_cummin)].to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean_mz_diff']  = df.mz_diff.rolling(window = 31, center=True, win_type ='cosine' ).mean() # note win_type =should be tukey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mz_std']  = df.mz_diff.rolling(window = 31, center=True ).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['lenset'] = df.rolling(31)['scan_id_f'].apply(lambda s:len(set(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ucounter(scanids_start,scanids_end, window_size):\n",
    "    sid_cts = np.zeros(window_size+1, dtype=np.int64)\n",
    "    uct = 0\n",
    "    for scanid_start,scanid_end in zip(scanids_start,scanids_end):\n",
    "        sid_cts[scanid_start] +=1\n",
    "        if sid_cts[scanid_start] ==1:\n",
    "            uct += 1\n",
    "        sid_cts[int(scanid_end)] -=1\n",
    "        if sid_cts[int(scanid_end)] ==0:\n",
    "            uct -= 1\n",
    "        yield uct\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.scan_id_f.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df['ucounter'] = list(ucounter(df.scan_id_f.to_numpy(),df.scan_id_f.shift(31).fillna(31).to_numpy(), 31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['uniq=_size'] = df.rolling(31)['scan_id_f'].apply(lambda s:np.unique(s).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nunique_scans.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean_diff'] = df['mz'].diff(-1).rolling(56).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mz_r'] = (df.mz / 10).round() *10\n",
    "\n",
    "valids = df.loc[df['nunique_scans'] >= 56 * 0.9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valids['resolution'] = valids['mz'] / valids['mean_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valids.sort_values('mz', inplace = True)\n",
    "valids['max_diff'] = valids['mean_diff'].cummax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valids.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valids.groupby('mz_r')['resolution'].min().to_frame().reset_index().plot(x='mz_r', y=\"resolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_resolution_and_gradient(spectra_df):\n",
    "    df = spectra_df.loc[spectra_df.precursor_id.isna()]\n",
    "    scan_count = df.scan_id.unique().size\n",
    "\n",
    "    df['scan_id_f'] = df['scan_id'].factorize()[0]\n",
    "    df.sort_values(['mz','scan_id_f'], ascending=False, inplace=True)\n",
    "    df['nunique_scans'] = df.rolling(60)['scan_id_f'].apply(lambda s:len(set(s)))\n",
    "    max_unique_scans = df['nunique_scans'].max()\n",
    "    df['mean_diff'] = df['mz'].diff(-1).rolling(max_unique_scans).mean()\n",
    "    df['mz_r'] = (df.mz / 10).round() *10\n",
    "\n",
    "    valids = df.loc[df['nunique_scans'] >= max_unique_scans * 0.9]\n",
    "    valids.sort_values('mz', inplace = True)\n",
    "    valids['max_diff'] = valids['mean_diff'].cummax()\n",
    "    selected = valids.groupby('mz_r')['resolution'].min().to_frame().reset_index()\n",
    "    # selected.plot(x='mz_r', y=\"resolution\")\n",
    "    res_at_loest_mass = selected['resolution'].iat[0]\n",
    "    gradient = selected['resolution'].iat[-1] - selected['resolution'].iat[0 ] / selected['mz_r'].iat[-1] - selected['mz_r'].iat[0 ]\n",
    "    return  res_at_loest_mass, gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diff'] = df['mz'].diff(-1)\n",
    "low,high = df['diff'].quantile([.20,.80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mzs = spectra_df.loc[spectra_df.precursor_id.isna()].mz.sort_values(ascending= False).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mzs['difs'] = mzs['mz'].diff(-1).replace(0,np.nan).fillna(method = 'bfill').fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low,high = mzs['difs'].quantile([.20,.80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mzs.loc[mzs['difs'].between(low,high), 'difs'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mzs['cummin'] = mzs['difs'].cummin() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mzs.groupby('cummin')['mz'].last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_tolerences.index.rename('da', inplace=True)\n",
    "absolute_tolerences.reset_index(inplace=True)\n",
    "absolute_tolerences['resolution'] = absolute_tolerences['mz'] / absolute_tolerences['da']\n",
    "absolute_tolerences['mz'] = (absolute_tolerences['mz'] / 10).round() *10\n",
    "absolute_tolerences['resolution'] = absolute_tolerences['resolution'].cummin()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_tolerences.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_tolerences = absolute_tolerences.groupby('mz')['resolution'].min().to_frame()\n",
    "absolute_tolerences.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_tolerences.plot(x='mz',y='resolution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_selection_window (spectra_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_less_std = agg_data.at['mean'] - agg_data.at['std']\n",
    "if mean_less_std > 0:\n",
    "    res =  mean_less_std / 2\n",
    "else:\n",
    "    res =  agg_data.at['mean'] /2\n",
    "\n",
    "return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_fuzzy(spectra_df):\n",
    "    fraction_of_average_intensity = 0.1\n",
    "    spectras_sum_inty =  spectra_df.loc[spectra_df.precursor_id.isna()].groupby('scan_id')['inty'].sum()\n",
    "    sum_inty_mean = spectras_sum_inty.mean()\n",
    "    spectras_sum_inty = spectras_sum_inty.to_dict()\n",
    "\n",
    "    to_drop = []\n",
    "    for scan_id in spectra_df.scan_id.drop_duplicates(): # this maintains order\n",
    "        if spectras_sum_inty[scan_id] < sum_inty_mean * fraction_of_average_intensity: # one order \n",
    "            to_drop.append(scan_id)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return spectra_df.loc[~spectra_df.scan_id.isin(to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spectra_dfs[0] # first file, already teim range and mass range filtered\n",
    "ms1_peaks = df.loc[df.precursor_id.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stem.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_linear_alignment(masses, options):\n",
    "    # TODO assert masses are ordered\n",
    "    up_to = None\n",
    "    for _, mass in masses.iteritems():\n",
    "        if up_to is None:\n",
    "            #up_to = mass + tolerance.getTinDA(mass) this is how its done in some places, but reuslt are not identical to below\n",
    "            up_to = mass + mass / options[\"MSresolution\"].tolerance \n",
    "        if mass <= up_to:\n",
    "            yield up_to\n",
    "        else:\n",
    "            up_to = mass + mass / options[\"MSresolution\"].tolerance\n",
    "            yield up_to\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ms1 agg peaks similar to lx1...ms1_peaks_agg\n",
    "# ms1 agg peaks as in lx2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms1_peaks.sort_values(\"mz\", ascending=False)\n",
    "scan_id_f = pd.factorize(ms1_peaks.scan_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "scan_id_f = pd.factorize(ms1_peaks.scan_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins1 = list(bin_linear_alignment(df.mz, options))\n",
    "bins2 = list(bin_linear_alignment(df.groupby(bins1)[\"mz\"].transform(\"mean\"), options))\n",
    "bins3 = list(bin_linear_alignment(df.groupby(bins2)[\"mz\"].transform(\"mean\"),options))\n",
    "\n",
    "df['bin_mass'] = bins3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms1_peaks_agg(ms1_peaks, options):\n",
    "    ms1_peaks.sort_values(\"mz\", inplace=True)\n",
    "\n",
    "    # binning is done 3 times in lx1, between each fadi filter is performed, we do it at the end intead\n",
    "    bins1 = list(bin_linear_alignment(ms1_peaks.mz, options))\n",
    "    bins2 = list(bin_linear_alignment(ms1_peaks.groupby(bins1)[\"mz\"].transform(\"mean\"), options))\n",
    "    bins3 = list(bin_linear_alignment(ms1_peaks.groupby(bins2)[\"mz\"].transform(\"mean\"),options))\n",
    "\n",
    "    ms1_peaks['bin_mass'] = bins3 \n",
    "\n",
    "    # merge mutiple peaks from single scan\n",
    "    g = ms1_peaks.groupby([\"bin_mass\", \"scan_id\"])\n",
    "    ms1_peaks[\"scan_cumcount\"] = g.cumcount()\n",
    "    ms1_peaks[\"merged_mass\"] = g[\"mz\"].transform(\"mean\")\n",
    "    ms1_peaks['merged_inty'] = g['inty'].transform(\"mean\") # NOTE merge is NOT weighted average \n",
    "    \n",
    "\n",
    "    # aggregate results\n",
    "    agg_df = (\n",
    "        ms1_peaks.loc[ms1_peaks.scan_cumcount == 0] # use only the first of merged masses\n",
    "        .assign(\n",
    "            mass_intensity=lambda x: x.mz * x.merged_inty\n",
    "        )  # for the weighted average intensity\n",
    "        .groupby(\"bin_mass\")\n",
    "        .agg(\n",
    "            {\n",
    "                \"merged_mass\": [\"mean\", \"count\"],\n",
    "                \"merged_inty\": [\"mean\", \"sum\"],\n",
    "                \"mass_intensity\": \"sum\",\n",
    "            }\n",
    "        )\n",
    "        .dropna()\n",
    "    )\n",
    "    agg_df.columns = [\"_\".join(col).strip() for col in agg_df.columns.values]\n",
    "\n",
    "    # apply fadi filters, in lx1 its done between each bin  process\n",
    "    fadi_denominator = ms1_peaks.scan_id.unique().shape[0]\n",
    "    mask_ff = agg_df.merged_mass_count / fadi_denominator >= options['MSfilter']\n",
    "    agg_df = agg_df[mask_ff]\n",
    "\n",
    "    # NOTE intensity threshold is do in add_Sample... but lets do it here\n",
    "    MSthreshold  = options[\"MSthreshold\"]\n",
    "    mask_inty = agg_df.merged_inty_mean > MSthreshold\n",
    "    agg_df = agg_df[mask_inty]\n",
    "\n",
    "    # for reference...weigted_mass shoud not be necesary\n",
    "    agg_df[\"weigted_mass\"] = agg_df.mass_intensity_sum / agg_df.merged_inty_sum\n",
    "    # lx1 intensity is wrong because it uses the total number of scans, instead of the numebr of scans with a peak\n",
    "    agg_df['lx1_bad_inty'] = agg_df.merged_inty_sum / fadi_denominator\n",
    "\n",
    "    \n",
    "    agg_df.rename(columns = {'merged_mass_mean':'mz', 'merged_inty_mean':'inty'}, inplace=True)\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_dfs[0].polarity.iat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for df in spectra_dfs: # first file, already teim range and mass range filtered\n",
    "    ms1_peaks = df.loc[df.precursor_id.isna()]\n",
    "    agg_df = ms1_peaks_agg(ms1_peaks, options)\n",
    "    agg_df['stem'] = df.stem.iloc[0]\n",
    "    res[df.stem.iloc[0]] = agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recalibrate\n",
    "def recalibrate_mzs(mzs, cals):\n",
    "    # from lx2_masterscan\n",
    "    # lx1 takes all that are within tolerance and then uses highest intensity\n",
    "    if not cals or mzs.empty:\n",
    "        return mzs\n",
    "    cal_matchs = [mzs.loc[mzs.sub(cal).abs().idxmin()] for cal in cals]\n",
    "    \n",
    "    cal_vals = [cal - cal_match for cal, cal_match in zip(cals, cal_matchs)]\n",
    "    # prefilter\n",
    "    if not any((v < 0.1 for v in cal_vals)):\n",
    "        return mzs\n",
    "    # find near tolerance\n",
    "    cutoff = mzs.diff(-1).quantile(0.1)\n",
    "    is_near = [v < cutoff for v in cal_vals]\n",
    "    if not any(is_near):\n",
    "        log.info(\"no valid calibration masses found\")\n",
    "        return mzs\n",
    "\n",
    "    cal_matchs = [e for e, v in zip(cal_matchs, is_near) if v]\n",
    "    cal_vals = [e for e, v in zip(cal_vals, is_near) if v]\n",
    "    log.debug(\"recalibration info: {'\\n'.join(zip(cal_matchs,cal_vals ))}\")\n",
    "\n",
    "    return mzs + np.interp(mzs, cal_matchs, cal_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align ms1 \n",
    "ms1_agg_peaks = pd.concat(res.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms1_agg_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one uses delta res for clustering\n",
    "def bin_mkSurveyLinear(masses, options):\n",
    "    # TODO assert masses are ordered\n",
    "    minmass = masses.iloc[0]\n",
    "    up_to = None\n",
    "    for _, mass in masses.iteritems():\n",
    "        if up_to is None:\n",
    "            #up_to = mass + tolerance.getTinDA(mass) this is how its done in some places, but reuslt are not identical to below\n",
    "            deltatol = options[\"MSresolution\"].tolerance + (mass - minmass) * options['MSresolutionDelta']\n",
    "            up_to = mass + (mass / deltatol)\n",
    "        if mass <= up_to:\n",
    "            yield up_to\n",
    "        else:\n",
    "            deltatol = options[\"MSresolution\"].tolerance + (mass - minmass) * options['MSresolutionDelta']\n",
    "            up_to = mass + (mass / deltatol)\n",
    "            yield up_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the method here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms1_agg_peaks.sort_values('mz', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning is done 3 times in lx1, between each fadi filter is performed, we do it at the end intead\n",
    "bins1 = list(bin_mkSurveyLinear(ms1_agg_peaks.mz, options))\n",
    "bins2 = list(bin_mkSurveyLinear(ms1_agg_peaks.groupby(bins1)[\"mz\"].transform(\"mean\"), options))\n",
    "bins3 = list(bin_mkSurveyLinear(ms1_agg_peaks.groupby(bins2)[\"mz\"].transform(\"mean\"),options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms1_agg_peaks['bins'] = bins3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check occupation spectracontainer.py masterscan.chekoccupation\n",
    "# occupation is the % of peak intensities abvove \"thrsld: \"\n",
    "threshold_denominator = ms1_agg_peaks.stem.unique().shape[0] # same as len(res)\n",
    "threshold = options[\"MSminOccupation\"]\n",
    "bin_peak_count = ms1_agg_peaks.groupby('bins')['inty'].transform('count')\n",
    "tf_mask = (bin_peak_count / threshold_denominator) >= threshold\n",
    "ms1_agg_peaks['above_threshold'] = tf_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms1_agg_peaks['mass'] = ms1_agg_peaks.groupby('bins')['mz'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms1_agg_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms1_agg_peaks.pivot(index='mass', columns='stem', values=['inty','lx1_bad_inty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO collape_join_adjecent_clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS2 \n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options[\"MSMSresolution\"]\n",
    "options[\"selectionWindow\"]\n",
    "\n",
    "#tolerance = TypeTolerance(\"Da\", scan.options[\"selectionWindow\"])\n",
    "#window = scan.options[\"selectionWindow\"] / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spectra_dfs[1] # first file, already teim range and mass range filtered\n",
    "ms2_peaks = pd.concat((df.loc[~df.precursor_id.isna()] for df in spectra_dfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ms2_peaks[ms2_peaks.scan_id == 'controllerType=0 controllerNumber=1 scan=41']  \n",
    "*** NOTE masses are not exactly the same as in lx1, they are wrong base om raw ***  \n",
    "see xcel file on desktop  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** lx1 does the precursor binning all files, at the same time, it is not like with the ms1s ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_linear_alignment_for_ms2(masses, telerance_da):\n",
    "    # TODO assert masses are ordered\n",
    "    up_to = None\n",
    "    for _, mass in masses.iteritems():\n",
    "        if up_to is None:\n",
    "            #up_to = mass + tolerance.getTinDA(mass) this is how its done in some places, but reuslt are not identical to below\n",
    "            up_to = mass + telerance_da\n",
    "        if mass <= up_to:\n",
    "            yield up_to\n",
    "        else:\n",
    "            up_to = mass + telerance_da\n",
    "            yield up_to\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouped_precursors_df(ms2_peaks):\n",
    "    ms2_peaks.sort_values(['precursor_mz','mz'], inplace=True)\n",
    "    precursors_df = ms2_peaks[[\"stem\", 'scan_id', 'precursor_mz']].drop_duplicates()# similar to unqie but return a series instead of an array\n",
    "    # using \"stem\", 'scan_id' to replicate the numebr of instances for the averaging later\n",
    "    \n",
    "    bins1 = list(bin_linear_alignment_for_ms2(precursors_df.precursor_mz, options[\"selectionWindow\"]))\n",
    "    bins2 = list(bin_linear_alignment_for_ms2(precursors_df.groupby(bins1)['precursor_mz'].transform('mean'), options[\"selectionWindow\"]))\n",
    "    bins3 = list(bin_linear_alignment_for_ms2(precursors_df.groupby(bins2)['precursor_mz'].transform('mean'), options[\"selectionWindow\"]))\n",
    "\n",
    "    precursors_df['prec_bin'] = bins3\n",
    "\n",
    "# no fadi filter for precursors  \n",
    "# after groupinbg the precursors, the groups are split on the \"sample\" ie the file,  \n",
    "# the each split of the group is merged in the __def mergeListsMsms__ method that uses linear alignment  \n",
    "# thats why... prec_ms2_peaks = ms2_peaks[(ms2_peaks.precursor_mz == t) & (ms2_peaks.stem == '190321_Serum_Lipidextract_368723_01')]\n",
    "    return precursors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precursors_df = grouped_precursors_df(ms2_peaks)\n",
    "precursors_bins = precursors_df.set_index('precursor_mz')['prec_bin'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precursors_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in def linearAlignment the var clusterToMerge, it only takes the \"sample\" if its not in the cluster, so no duplicate, and only the first \"sample\"\n",
    "\n",
    "for clutering ms2 precursors, it does the binning with linearAlignment... see above, its not the unique precusrsor, its each precursor in each file,  but it does the binning on both at the same time, in contrast to how its done for ms1 binning, where first the binning is done for one file and then for the other.\n",
    "\n",
    "then it does the merge it on a per file (AKA \"sample\")  basis, merge means doing a linera alignmebt on all the peaks in the bin per sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms2_peaks['prec_bin'] = ms2_peaks.precursor_mz.map(precursors_bins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one uses delta res for clustering\n",
    "def bin_mkSurveyLinear_for_ms2(masses, options): # copied from above\n",
    "    # TODO assert masses are ordered\n",
    "    minmass = masses.iloc[0]\n",
    "    up_to = None\n",
    "    for _, mass in masses.iteritems():\n",
    "        if up_to is None:\n",
    "            #up_to = mass + tolerance.getTinDA(mass) this is how its done in some places, but reuslt are not identical to below\n",
    "            deltatol = options[\"MSMSresolution\"].tolerance + (mass - minmass) * options['MSMSresolutionDelta']\n",
    "            up_to = mass + (mass / deltatol)\n",
    "        if mass <= up_to:\n",
    "            yield up_to\n",
    "        else:\n",
    "            deltatol = options[\"MSMSresolution\"].tolerance + (mass - minmass) * options['MSMSresolutionDelta']\n",
    "            up_to = mass + (mass / deltatol)\n",
    "            yield up_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms2_peaks_group_generator(grouped_prec, options):\n",
    "\n",
    "    for idx, prec_ms2_peaks in  grouped_prec:\n",
    "        #intensityWeightedAvg\n",
    "        prec_ms2_peaks.sort_values('mz', inplace=True)\n",
    "        bins1 = list(bin_mkSurveyLinear_for_ms2(prec_ms2_peaks.mz, options))\n",
    "        bins1_weighted_average = (prec_ms2_peaks.mz * prec_ms2_peaks.inty).groupby(bins1).transform('sum') / prec_ms2_peaks.inty.groupby(bins1).transform('sum')\n",
    "        bins2 = list(bin_mkSurveyLinear_for_ms2(bins1_weighted_average, options))\n",
    "        bins2_weighted_average = (prec_ms2_peaks.mz * prec_ms2_peaks.inty).groupby(bins2).transform('sum') / prec_ms2_peaks.inty.groupby(bins2).transform('sum')\n",
    "        bins3 = list(bin_mkSurveyLinear_for_ms2(bins2_weighted_average, options))\n",
    "        weighted_mass = (prec_ms2_peaks.mz * prec_ms2_peaks.inty).groupby(bins3).transform('sum') / prec_ms2_peaks.inty.groupby(bins3).transform('sum')\n",
    "\n",
    "        prec_ms2_peaks['bins'] = bins3\n",
    "        prec_ms2_peaks['weighted_mass'] = weighted_mass\n",
    "\n",
    "        fadi_denominator = prec_ms2_peaks.scan_id.unique().shape[0]\n",
    "        ff_mask = prec_ms2_peaks.groupby(\"bins\")['bins'].transform('count') / fadi_denominator>= options['MSMSfilter']\n",
    "        mof_mask = prec_ms2_peaks.groupby(\"bins\")['bins'].transform('count') / fadi_denominator>= options['MSMSminOccupation']\n",
    "\n",
    "        tf_mask = prec_ms2_peaks.inty > options[\"MSMSthreshold\"]\n",
    "        \n",
    "        # it uses merge sum intensity for getting the averrage intensity...\n",
    "        agg_prec_ms2_peaks = prec_ms2_peaks[ff_mask & tf_mask & mof_mask].groupby('bins').agg({\"weighted_mass\":['mean', 'count'],\"inty\":\"mean\"})\n",
    "        agg_prec_ms2_peaks['precursor_mz'] = prec_ms2_peaks.precursor_mz.mean().round(6) \n",
    "        # there is minor differrence in mean between different files, and the same precursor bin, to avoid it we round\n",
    "        \n",
    "        agg_prec_ms2_peaks['stem'] = idx[0]\n",
    "\n",
    "        agg_prec_ms2_peaks.columns = [\"_\".join(col).strip() for col in agg_prec_ms2_peaks.columns.values]\n",
    "        names = {'weighted_mass_mean':'mz',\n",
    "         'weighted_mass_count':'count', \n",
    "         \"inty_mean\":'inty',\n",
    "         'precursor_mz_':'precursor_mz',\n",
    "         'stem_':'stem'}\n",
    "        agg_prec_ms2_peaks.rename(columns = names, inplace=True)\n",
    "\n",
    "        yield agg_prec_ms2_peaks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms2_peaks.prec_bin.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_prec = ms2_peaks.groupby(['stem','prec_bin'])\n",
    "ms2_agg_peaks = pd.concat(ms2_peaks_group_generator(grouped_prec, options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collape_join_adjecent_clusters_msms(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# associate ms2 to ms1 scans... \n",
    "ms1_masses = ms1_agg_peaks.mass.drop_duplicates()\n",
    "precur_masses = ms2_agg_peaks.precursor_mz.drop_duplicates()\n",
    "tol = options[\"selectionWindow\"] / 2\n",
    "tmp = pd.merge_asof(ms1_masses, precur_masses.astype(ms1_masses.dtype), left_on='mass', right_on='precursor_mz', direction ='nearest' , tolerance=tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms1_agg_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the masterscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lx.spectraContainer import MasterScan\n",
    "from LX2_masterscan import se_factory, ms2entry_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_inty_generator_ms1_agg(ms1_agg_peaks):\n",
    "    for mass, gdf in ms1_agg_peaks.groupby('mass'):\n",
    "        dictIntensity = gdf.set_index('stem')['lx1_bad_inty'].to_dict()\n",
    "        dictIntensity_lx2 = gdf.set_index('stem')['inty'].to_dict()\n",
    "        dictIntensity.update({ f'{k}_lx2':v for k,v in dictIntensity_lx2.items()})\n",
    "        yield (mass, dictIntensity, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = samples[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.extend([f'{k}_lx2' for k in samples]) #because we add both results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listSurveyEntry = [\n",
    "        se_factory(msmass, dictIntensity, samples, polarity)\n",
    "        for msmass, dictIntensity, polarity in mass_inty_generator_ms1_agg(\n",
    "            ms1_agg_peaks\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSMSEntry_list_generator(gdf):\n",
    "    for mz,  precur_df in gdf.groupby('mz'):\n",
    "        dictIntensity = precur_df.set_index('stem')['inty'].to_dict()\n",
    "        dictIntensity.update({ f'{k}_lx2':v for k,v in dictIntensity.items()}) #TODO actually get other values\n",
    "        yield (mz, dictIntensity, samples, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MS2_dict_generator(ms2_agg_peaks):\n",
    "    for precursor_mz, gdf in ms2_agg_peaks.groupby('precursor_mz'):\n",
    "        MSMSEntry_list = [ms2entry_factory(*args) for args in MSMSEntry_list_generator(gdf)]\n",
    "        yield (precursor_mz, MSMSEntry_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS2_dict = dict(MS2_dict_generator(ms2_agg_peaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS2_dict_keys =pd.Series(list(MS2_dict.keys()), name = 'MS2_precurs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS2_dict_keys.sort_values(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS1_precurmass =pd.Series([se.precurmass for se in listSurveyEntry], name = 'MS1_precurmass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MS1_precurmass.sort_values(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# associate ms2 to ms1 scans\n",
    "tol = options[\"selectionWindow\"] / 2\n",
    "precur_map_df = pd.merge_asof(MS1_precurmass, MS2_dict_keys, left_on='MS1_precurmass' , right_on='MS2_precurs',direction ='nearest' , tolerance=tol)\n",
    "# tmp = pd.merge_asof(ms1_masses, ms1_masses.dtype, left_on='mass', right_on='precursor_mz', direction ='nearest' , tolerance=tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precur_dict = precur_map_df.set_index(MS1_precurmass)['MS2_precurs'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(precur_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms1_prec_dict = ms1_agg_peaks.set_index('mass')['precursor_mz'].to_dict()\n",
    "for se in listSurveyEntry:\n",
    "    precursor = precur_dict[se.precurmass]\n",
    "    print(len(MS2_dict.get(precursor,[])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add data to masterscan\n",
    "scan = MasterScan(options)\n",
    "scan.listSurveyEntry = listSurveyEntry\n",
    "scan.listSurveyEntry[0].massWindow = 0.01  # to avoid bug\n",
    "scan.sampleOccThr[\"MS\"] = [(0.0, [])]  # to avoid bug at def checkOccupation\n",
    "scan.sampleOccThr[\"MSMS\"] = [(0.0, [])]\n",
    "\n",
    "# for printing we need\n",
    "# samples.extend([f'{k}_lx2' for k in samples])\n",
    "scan.listSamples = samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tmp_lx1_and_lx2.sc','wb') as f: pickle.dump(scan, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recalibrate\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ms1_dfs.pkl', 'rb') as f: ms1_dfs = pickle.load(f)\n",
    "with open('options.pkl', 'rb') as f: options = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recalibrate\n",
    "def recalibrate_mzs(mzs, cals):\n",
    "    # from lx2_masterscan\n",
    "    # lx1 takes all that are within tolerance and then uses highest intensity\n",
    "    if not cals or mzs.empty:\n",
    "        return mzs\n",
    "    cal_matchs = [mzs.loc[mzs.sub(cal).abs().idxmin()] for cal in cals]\n",
    "\n",
    "    cal_vals = [cal - cal_match for cal, cal_match in zip(cals, cal_matchs)]\n",
    "    # prefilter\n",
    "    if not any((v < 0.1 for v in cal_vals)):\n",
    "        return mzs\n",
    "    # find near tolerance\n",
    "    cutoff = mzs.diff(-1).quantile(0.1)\n",
    "    is_near = [v < cutoff for v in cal_vals]\n",
    "    if not any(is_near):\n",
    "        log.info(\"no valid calibration masses found\")\n",
    "        return mzs\n",
    "\n",
    "    cal_matchs = [e for e, v in zip(cal_matchs, is_near) if v]\n",
    "    cal_vals = [e for e, v in zip(cal_vals, is_near) if v]\n",
    "    log.debug(\"recalibration info: {'\\n'.join(zip(cal_matchs,cal_vals ))}\")\n",
    "\n",
    "    return mzs + np.interp(mzs, cal_matchs, cal_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for cal_mass in options['MScalibration']:\n",
    "    tol = cal_mass / options[\"MSresolution\"].tolerance\n",
    "    #find close enough most intense\n",
    "    reference_mass = ms1_df[ms1_df.mz.between(cal_mass-tol , cal_mass+tol)].sort_values('inty', ascending=False).mz.iat[0]\n",
    "    change_val = cal_mass - reference_mass\n",
    "    res.append((reference_mass, change_val))\n",
    "\n",
    "cal_matchs, cal_vals = zip(*res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perf testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('stitched.sc','wb') as f: pickle.dump(stitched, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stitched.sc','rb') as f: stitched  = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitched.dump('stitched-dump.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = stitched.listSurveyEntry[0]\n",
    "t.dictIntensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ms2_peaks.pkl','rb') as f: ms2_peaks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms2_peaks[['precursor_mz', 'prec_bin']].drop_duplicates()['prec_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 ('lx128_p3_Dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "06b28214ce0e3c48e23cdf5811c1f91197bed88289d9fe34e9aeb8dd4305abb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
